<!DOCTYPE html>
<html lang="en">

    <head>
        <link href="/assets/built/jekyll-style.css" rel="stylesheet">
          <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Train Your Ninja</title>
  <meta name="description" content="Ninja Gaiden is a nightmare game when I was kid… TL;DR">

  
  <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
  <link rel='stylesheet' href='/css/terminal.css'>  

  <script defer type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?..."></script>
  <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
  messageStyle: "none"
});
  </script>

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="/jekyll/update/2018/12/23/play-ninja-gaiden.html">
  <link rel="alternate" type="application/rss+xml" title="Zeng&#39;s Home Page" href="/feed.xml">

  

    </head>

  <body style="overflow: hidden;">

    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header">
      
    



<header id="header" class="mdl-layout__header mdl-layout__header--fixed-header portfolio-header ">
    <div class="mdl-layout__header-row portfolio-navigation-row mdl-layout--large-screen-only">
        <span class="mdl-layout__title">
            <div class="portfolio-logo"></div>
        </span>
        <span class="mdl-layout__title portfolio-title">
            Zeng&#39;s Home Page
        </span>
        
        <nav class="mdl-navigation mdl-typography--body-1-force-preferred-font col-md-6 col-lg-9">
          
            
            
          
            
            
          
            
            
          
            
            
            <a class="mdl-navigation__link mdl-button mdl-js-button" style="color:black;text-decoration:none;" href="/">Home</a>
            
          
            
            
            <a class="mdl-navigation__link mdl-button mdl-js-button" style="color:black;text-decoration:none;" href="/project/">Project</a>
            
          
            
            
            <a class="mdl-navigation__link mdl-button mdl-js-button" style="color:black;text-decoration:none;" href="/blog/">Blog</a>
            
          
            
            
            <a class="mdl-navigation__link mdl-button mdl-js-button" style="color:black;text-decoration:none;" href="/about/">About</a>
            
          
        </nav>
        <div style="font-size:30px;margin-left:5px;">
        <a class="fa fa-github-alt falink" aria-hidden="true" href="https://github.com/daizeng1984"></a>
        <a class="fa fa-linkedin-square falink" aria-hidden="true" href="https://www.linkedin.com/in/zeng-dai-3950a245/"></a>
        <a class="fa fa-facebook-official falink" aria-hidden="true" href="https://www.facebook.com/zeng.dai"></a>
        </div>
    </div>
    <!-- <div class="blurheader"> -->
    <!-- </div> -->
    <div class="mdl-layout__title portfolio-title mdl-layout--small-screen-only">
        Zeng&#39;s Home Page
    </div>
    <div id="header-background" class="portfolio-background">
    </div>
</header>
<div class="mdl-layout__drawer mdl-layout--small-screen-only">
    <nav class="mdl-navigation mdl-typography--body-1-force-preferred-font">
          
            
            
          
            
            
          
            
            
          
            
            
            <a class="mdl-navigation__link mdl-button mdl-js-button" href="/">Home</a>
            
          
            
            
            <a class="mdl-navigation__link mdl-button mdl-js-button" href="/project/">Project</a>
            
          
            
            
            <a class="mdl-navigation__link mdl-button mdl-js-button" href="/blog/">Blog</a>
            
          
            
            
            <a class="mdl-navigation__link mdl-button mdl-js-button" href="/about/">About</a>
            
          
    </nav>
</div>


    <main class="mdl-layout__content page-content" aria-label="Content">
      <div>
          <div class="mdl-grid portfolio-max-width">
              <div class="mdl-cell mdl-cell--12-col mdl-card mdl-shadow--4dp">
                  <div class="mdl-card__media main-header">
                      
                      <h2 class="mdl-card__title-text main-title" ><i class="fa fa-window-maximize" aria-hidden="true"></i></h2>
                      
                  </div>
                  <div class="mdl-grid mdl-cell--12-col portfolio-copy">
    
    
    
    
    
    
    <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

        <header class="post-header">
            <h1 class="post-title" itemprop="name headline">Train Your Ninja</h1>
            <p class="post-meta">
                <time datetime="2018-12-23T21:53:01-08:00" itemprop="datePublished">
                    
                    Dec 23, 2018
                </time>
                </p>
        </header>

        <div class="post-content" itemprop="articleBody">
            <p>Ninja Gaiden is a nightmare game when I was kid… <a href="/jekyll/update/2018/12/23/play-ninja-gaiden.html#a-few-rough-ideas-so-far">TL;DR</a></p>

<h1 id="ninja-gaiden">Ninja Gaiden</h1>

<p>This is the ninja game for real ninja. Jump &amp; slash, swift moving and never hesitate. I cannot beat this game as a kid and still struggle today. But now <a href="https://deepmind.com/research/dqn/">dqn</a> sounds so powerful that we probably got some chances?</p>

<p class="image-caption"><img src="/assets/images/blog/2018/ninja-gaiden.jpg" alt="ninja-gaiden" width="30%" class="img-thumbnail center-block" />
Ninja Gaiden, from Tecmo</p>

<h1 id="wait">Wait…</h1>
<p>There Are Already a Lot of Nice Stuff for these type of games e.g. Super Mario Bros. It looks this problem is solved (AI beats human). However they are not ninja gaiden ☺︎ . This game is quite special and different from game like super mario. It’s unfriendly to beginner; it has complicate scenes (visually, e.g. strange climb detection and bounding box); it has a few glitches/techniques (multiple slashes, air floor, and damage boost) that makes interesting for AI to explore; a lot of different powerup weapons and <code class="highlighter-rouge">ninpo</code>; … Most importantly, having finished readings on this great <a href="https://simoninithomas.github.io/Deep_reinforcement_learning_Course/">intro</a> website (recommend for beginner of reinforcement learning), it makes me very curious to see whether career of Ryu/ninja can be replaced by state of art reinforcement learning agent.</p>

<h1 id="openai-gym">OpenAI Gym</h1>
<p><a href="https://gym.openai.com/">Gym</a> is the environment created to train AI on many different games. NES game’s Gym is not officially supported due to some reasons. The quick search leads me to the work like <a href="https://www.youtube.com/watch?v=qv6UVOQ0F44">Mario NEAT</a> that uses the Lua script on <a href="http://www.fceux.com/web/home.html">Fceux</a>. Not a fan of Lua, so I started to look for something in Python.</p>

<p>Finally, I end up with <a href="https://github.com/Kautenja/nes-py">nes-py</a>, which is very pythony and have <a href="https://github.com/Kautenja/nes-py/wiki/Creating-Environments">wiki</a> to help build your own environment. Even though I ran into some trouble building the nes-py package because python setuptools requires some strange CXXFLAGS (-flto-partition=None) that my clang doesn’t like, but eventually I manually built this package with some hacky way in pip temp folders and moved around the *.so in nes-py package. BTW, the author of nes-py also have an example of Super Mario Bro’s nes environment, check <a href="https://github.com/Kautenja/nes-py/wiki/Creating-Environments">it</a> out if interested.</p>

<h1 id="hack-into-ninja-gaiden">Hack into Ninja Gaiden</h1>
<p>Now we need to know where (memory address) is the data (e.g. hit point). Thanks to gamers, we have a nice website named <a href="http://tasvideos.org/GameResources/NES/NinjaGaiden.html">TASVideo</a> documenting a lot. But be aware some of them are not precise enough. For example, to get the x position of Ryu, I checked many the memory location and eventually figured it out it’s a fixed point 3-bit float instead of the 2-bit screen position as in document.</p>

<h1 id="agents">Agents</h1>
<p>Now let’s go down to business. I stolen a lot of code from internet <a href="https://github.com/jcwleo/mario_rl">here</a> and <a href="https://github.com/ikostrikov/pytorch-a2c-ppo-acktr/tree/master/a2c_ppo_acktr">there</a>. Again before diving, I’d suggest you read through this free intro <a href="https://simoninithomas.github.io/Deep_reinforcement_learning_Course/">course</a> to understand the basics of a2c, ppo etc.. I created a simple and cruel reward function to best encourage moving fast to end of the level. No reward to slash enemy or gain <code class="highlighter-rouge">ninpo</code> etc. because I really wanted to see an AI speedrunner.</p>

<p>Let’s first only focus on level 1-1.</p>

<p class="image-caption"><img src="/assets/images/blog/2018/ninja-struggles.gif" alt="ninja-learning-gaiden" width="100%" class="img-thumbnail center-block" />
Ninja Learning Gaiden</p>

<p>Here’s my shallow findings after 8 hours training (sorry slow computer) for different models:</p>
<ol>
  <li>PPO performs not as good as A2C</li>
  <li>A2C stopped maybe due to bugs</li>
  <li>A2C curiority works mostly and even finished the level 1</li>
</ol>

<p>As non-expert, for these models I cannot really judge good or bad, but only based on the implementation result. None of them surprise me as they did in Super Mario. They seems to be really confused even after training a while. Later probably I should try out the OpenAI’s newly published a2c models. But even with these little experience, I still could get some <code class="highlighter-rouge">the state-of-art</code> feeling.</p>

<h1 id="whats-promising">What’s Promising</h1>
<h2 id="climb-the-obstacle">Climb the Obstacle</h2>
<p>Most Agents will stop at the wall, because it doesn’t know how to get there. some can search some just cannot.
I’m amazed AI with curiosity can actually figure out the wall climb jump. For human, it’s really hard to do that since this behavior (control) is not quite human anyway.</p>

<p class="image-caption"><img src="/assets/images/blog/2018/ninja-climb.gif" alt="ninja-climb" width="30%" class="img-thumbnail center-block" />
Ninja can climb</p>

<h2 id="powerup-items">Powerup Items</h2>
<p>Also thumb up for the self-motivated behavior to slash the ninpo even though I didn’t give it as reward. Maybe the agent is just do it for fun ☺︎ .</p>

<p class="image-caption"><img src="/assets/images/blog/2018/ninja-blindly-powerup.gif" alt="ninja-powerup" width="30%" class="img-thumbnail center-block" />
Ninja blindly loves powerup :)</p>

<h2 id="finding-secretsbugs">Finding Secrets/Bugs</h2>
<p>AI even can jump on air floor which is usually done by speedrunners.</p>

<h1 id="challenges">Challenges</h1>
<h2 id="fight-tyson">Fight Tyson</h2>
<p>Tyson is annoying for AI and beginners too. Sometimes, AI is just like a scared cat in the tree.</p>

<h2 id="strategy-thinking">Strategy Thinking</h2>
<p>Probably Super Mario is no brainer game, player doesn’t need to think about strategy too much: all rewards can be achieved in very short time period or strategy is very easy to discover. But in this Ninja Gaiden, strategically gain Ninpo and other weapons can largely improve performance. Unfortunately, I didn’t see any hopes for all the models I tested.</p>

<h1 id="real-ninja-vs-ai">Real Ninja vs AI</h1>
<p>First of all, human are still fine. At this point, AI cannot beat human or even beginners with a few min training. A long way to go! Also depending on game’s genre, the more strategic the more hard for AI because they only have visual clues. Not like us, we’ve been educated from different kinds of source (visual, sound, feel…) since born. But AI can do really well in visual game and not suprisingly better than human because they can try different ways again and again and operate much faster than human.</p>

<p>Look at this <a href="https://youtu.be/OGZWkqdwfEI?t=8">speedrunner</a>, human’s proud!</p>

<h2 id="a-few-rough-ideas-so-far">A Few Rough Ideas So Far</h2>
<ol>
  <li>AI probably could have seen better given better emulator environment. NES game has limitation to show multiple enemy in same screen nor does it have alpha blending. You’ll see blinking sprite from time to time. This probably annoys AI a bit.</li>
  <li>Multitask or modularization (components) helps. For example a better visual detection to identify the enemy and a thinker network with more memory to think strategy.</li>
  <li>I feel curiosity is a key factor to avoid local optimal and we should keep trying a lot in limited time.</li>
  <li>Human teacher will definitely help boost the performance. This is perhaps why Go players like <a href="https://en.wikipedia.org/wiki/Lee_Sedol">Lee Sedol</a> cannot win AI cause we give them the optimal searching path we human found through years of training experience and computer is faster to process number/arithm than us <code class="highlighter-rouge">atop of our experience</code>. It’s not a fair game at all from this pov. But I really appreciate our Go players to help promote AI techniques. Same idea can apply if we have our speed runners to teach computer and then they can beat us by searching and improving the margins.</li>
  <li>Perhaps within our era, AI without a huge team behind is still primitive.</li>
  <li>Purely relying on visual clues is like we human only trust our vision hunch (muscle memory?). It won’t make us stand out in more strategical competition like <a href="http://www.dota2.com/">DoTA</a>. In these games, human sometimes can sacrifice some short time low reward to gain something bigger, and this experience is learnt from other resources after we are born.</li>
</ol>

<!--- # Resources
DISPLAY=:0.0 python run.py # Display is to solve the device none error
https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html
https://www.cs.ubc.ca/~gberseth/blog/category/project.html
https://github.com/udacity/deep-reinforcement-learning/blob/master/dqn/exercise/dqn_agent.py
--->


        </div>

        
        

        
    </article>
</div>

              </div>
      </div>
    <footer class="mdl-mini-footer">
    <div class="mdl-mini-footer__left-section">
        <div class="mdl-logo" style="color:#9e9e9e">Built with 
            <div id="thanksto" class="thanksto">
                <b class="disappear"><i class="fa fa-heart" aria-hidden="true"></i></b>
                
                <b class="disappear" href="https://jekyllrb.com/">Jekyll</b>
                
                <b class="disappear" href="http://getbootstrap.com/">Bootstrap</b>
                
                <b class="disappear" href="https://getmdl.io/">MDL</b>
                
                <b class="disappear" href="http://fontawesome.io">FontAwesome</b>
                
                <b class="disappear" href="https://www.mathjax.org/">MathJax</b>
                
                <b class="disappear" href="https://fslightbox.com/">FSLightbox</b>
                
                <b class="disappear" href="https://threejs.org/">ThreeJS</b>
                
                <b class="disappear" href="https://www.shadertoy.com/view/XdXcDf">ShaderToy</b>
                
                <div id="thanks_to_script"></div>
            </div>
        </div>
    </div>
    <div class="mdl-mini-footer__right-section">
        <ul class="mdl-mini-footer__link-list mdl-layout--large-screen-only">
            
            <li><a href="mailto:daizeng1984@gmail.com">daizeng1984@gmail.com</a></li>
            
            <li>Last Updated: 18-May-2019</li>
        </ul>
    </div>
</footer>

    </main>
    </div>

    <script type="text/javascript" src="/assets/built/jekyll-bundle.js" charset="utf-8"></script>

  </body>

</html>
