{"version":3,"sources":["webpack:///./src/components/posts-layout.js","webpack:///./src/posts/2019-05-14-system-design.mdx"],"names":["PostPage","props","icon","_frontmatter","layoutProps","MDXLayout","DefaultLayout","MDXContent","components","mdxType","parentName","isMDXComponent"],"mappings":"8FAAA,iDASeA,IAJE,SAACC,GAAD,OACb,kBAAC,IAAD,iBAAYA,EAAZ,CAAmBC,KAAK,Y,kLCEfC,EAAe,GACtBC,EAAc,CAClBD,gBAEIE,EAAYC,IACH,SAASC,EAAT,GAGZ,IAFDC,EAEC,EAFDA,WACGP,EACF,8BACD,OAAO,YAACI,EAAD,iBAAeD,EAAiBH,EAAhC,CAAuCO,WAAYA,EAAYC,QAAQ,cAG5E,gJACA,gCACA,6LAKA,+FACA,iCACA,sOACA,oJACA,4JACA,sBACE,kBAAIC,WAAW,MAAf,oBACA,kBAAIA,WAAW,MAAf,yBACA,kBAAIA,WAAW,MAAf,gCACA,kBAAIA,WAAW,MAAf,yBAEF,8CACA,oEACF,+BAAGA,WAAW,KAAQ,CAChB,KAAQ,uEADd,wEAOFH,EAAWI,gBAAiB","file":"component---src-posts-2019-05-14-system-design-mdx-186e9fd6d730968c2ff3.js","sourcesContent":["import React from \"react\"\nimport { Link } from \"gatsby\"\n\nimport Layout from './layout.js'\n\nconst PostPage = (props) => (\n    <Layout {...props} icon='post' />\n)\n\nexport default PostPage\n","import * as React from 'react'\n  /* @jsx mdx */\nimport { mdx } from '@mdx-js/react';\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\n\nimport DefaultLayout from \"/Users/zdai/Workspace/vimwiki/Projects/Blogger/blogv3/src/components/posts-layout.js\";\nexport const _frontmatter = {};\nconst layoutProps = {\n  _frontmatter\n};\nconst MDXLayout = DefaultLayout;\nexport default function MDXContent({\n  components,\n  ...props\n}) {\n  return <MDXLayout {...layoutProps} {...props} components={components} mdxType=\"MDXLayout\">\n\n\n    <p>{`As a builder, if you want to go to next level, you should learn how to build the whole building or even the whole city.`}</p>\n    <h1>{`Intros`}</h1>\n    <p>{`Big picture.\nLead the project.\nDelegate job\nResponsible\nKey is you've seen many cases and you know what's going to happen later. So you get everything prepared.`}</p>\n    <p>{`Case by Case, for series I we will start from very basic one: Crawler.`}</p>\n    <h2>{`Crawler`}</h2>\n    <p>{`Crawler seems to be so simple that looks like a course project from CS 101. However it can be really hard! Think about a huge engineering team in Google is trying to do this correct. So it's not that easy.`}</p>\n    <p>{`what's missing in our project? Let's get back to problem and this time we think it seriously considering all could happens.`}</p>\n    <p>{`System that visit one web page, and then extract the url from page content and then continue to traverse the url do similar things.`}</p>\n    <ol>\n      <li parentName=\"ol\">{`Scalability. WWW`}</li>\n      <li parentName=\"ol\">{`Distributed structure`}</li>\n      <li parentName=\"ol\">{`Adversary. robot spam site, `}</li>\n      <li parentName=\"ol\">{`Loop and Seen check.`}</li>\n    </ol>\n    <p>{`Stanford slides good!`}</p>\n    <p>{`We have some industrial case as show here:\n`}<a parentName=\"p\" {...{\n        \"href\": \"https://qbox.io/blog/scraping-the-web-with-nutch-for-elasticsearch\"\n      }}>{`https://qbox.io/blog/scraping-the-web-with-nutch-for-elasticsearch`}</a></p>\n\n    </MDXLayout>;\n}\n;\nMDXContent.isMDXComponent = true;\n      "],"sourceRoot":""}